\documentclass[11pt]{article}
\usepackage{amsfonts,amsmath}
\usepackage{latexsym}
\setlength{\oddsidemargin}{.0in}
\setlength{\evensidemargin}{.0in}
\setlength{\textwidth}{6.5in}
\setlength{\topmargin}{-0.4in}
\setlength{\textheight}{8.5in}


\begin{document}
\textbf{Keeyon Ebrahimi}\\
\textbf{N14193968}\\
\textbf{Homework 4}\\
\\ \\ \\
\textbf{Problem 2:}\\
\begin{enumerate}
\item[a) ] Lets look at the basic observation, $$P(A) + P(\overline{A}) = 1$$\\
This means that in the total array of possibilities, the Probability of A happening plus the Probability of A not happening is 1.\\ \\
When we say $$P(A\ |\ B)$$ \\ We are just limiting the total array of possibilities to set $B$.
This means that $$P(A\ |\ B) + P(\overline{A}\ |\ B) = 1$$
\begin{center}
 is the same as 
\end{center}
$$P(A) + P(\overline{A}) = 1$$ \\ \\
The only difference is that in the first statement, we are just limiting the total array of possibilities to B. \\ \\
To explain the drawing below, \textit{which is on the next page}, we have to look at a certain fact.
$$0 \leq P(A\ |\ B) \leq 1$$ 
\begin{center}
and 
\end{center}
$$0 \leq P(\overline{A}\ |\ B) \leq 1$$.
\\ Because we know the sum of these two probabilities is $1$, we know that either both probabilities will be between $0$ and $1$, or one probability will be $1$ leaving the other probability at $0$.  As you can see in the drawings below, for all three possibilities, if we fill out both $P(A\ |\ B)$ and $P(\overline{A}\ |\ B)$, we can see that the circle $B$ is always completely filled out, hence the sum of $P(A\ |\ B)$ and $P(\overline{A}\ |\ B)$ will equal 1.\\ \\ 
\newpage
\item[b) ]  We know that events $A_1$, $A_2$, and $A_3$ are all disjoint, but they span all possible values.  We know they are disjoint because all possible Unions have a size of $0$, as stated in the problem.  Knowing they are all disjoint, but they all still sum up to $1$, we know that events $A_1$, $A_2$, and $A_3$ span over all possible outcomes.\\ \\
In part A, $P(A) + P(\overline{A})$ spanned over the entire array of possible values, which was the basis of our proof.  Now we know that $P(A_1) + P(A_2) + P(A_3)$ span over the entire array of possible values. \\ \\
$P(A_1\ |\ B) + P(A_2\ |\ B) + P(A_3\ |\ B) = x$ is asking that in the subspace of $A_1 \cup A_2 \cup A_3$, how much of $B$ do we cover over?  Because $A_1 \cup A_2 \cup A_3$ is the entire subspace, we have to be covering over all of $B$, meaning that $$P(A_1\ |\ B) + P(A_2\ |\ B) + P(A_3\ |\ B) = 1$$
\end{enumerate}
\newpage
\textbf{Problem 3}
\\
\begin{center}
\textbf{Observation 1}
\end{center}
The probability of one heads and one tails is the sum of probability First coin heads and second coin tails, and the probability of First coin tails and second coin heads.

$$P[one\ heads,\ one\ tails] = P[H_1,T_2] + P[T_1, H_2]$$
\noindent\rule{20cm}{0.4pt}
\begin{center}
\textbf{Observation 2}
\end{center}
We also know that coin tosses are independent of each other.  What effects a coin toss result is the result of the dice roll, which is in turn not effected by a coin toss in any way, so Coin toss results are independent. This means that 
\\

$$ P[H_1, T_2] = P[H_1] * P[T_2]$$
\begin{center}
and
\end{center}
$$ P[T_1, H_2] = P[T_1] * P[H_2]$$
\noindent\rule{20cm}{0.4pt}
\begin{center}
\textbf{Observation 3}
\end{center}
We also know that coin flips can either be heads or tails, meaning that if we are not one result, we must be the opposite, so 
$$P[\overline{H_i}] = P[T_i]$$
\begin{center}
and
\end{center}
$$P[\overline{T_i}] = P[H_i]$$
\noindent\rule{20cm}{0.4pt}
\begin{center}
\textbf{Observation 4}
\end{center}

We also know that $P[A] + P[\overline{A}] = 1$, so building off of this and Observation 3, we know that
$$P[H_i] + P[T_i] = 1$$
\noindent\rule{20cm}{0.4pt}
Here are the math steps to solve now
\begin{enumerate}
\item[1. ] $P[one\ heads,\ one\ tails] = P[H_1,T_2] + P[T_1, H_2]$ \\
\item[2. ] $P[H_1, T_2] = P[H_1] * P[T_2]$\\
\item[3. ] $P[H_1] = 0.5$\\
\item[4. ] $P[T_2] = (P[D_0\ \leq 2] * P[T|C_0] ) + (P[D_0\ \geq 2] * P[T|C_1] )$\\
\item[5. ] $P[T_2] = (\frac{1}{3} * (0.5) + \frac{2}{3} * 0.2) = 0.3$\\
\item[6. ] $P[H_1, T_2] = P[H_1] * P[T_2] = 0.5 * 0.3 = 0.15$\\
\item[7. ] $P[T_1, H_2] = P[T_1] * P[H_2]$\\
\item[8. ] $P[T_1] = 0.5$\\
\item[9. ] $P[H_2] = (P[D_0\ \leq 2] * P[H|C_0] ) + (P[D_0\ \geq 2] * P[H|C_1] ) = P[\overline{T_2}]$\\
\item[10. ] $P[H_2] = (\frac{1}{3} * (0.5) + \frac{2}{3} * 0.8) = 0.7$ //As we can see, this is also the same as $P[\overline{T_2}]$\\
\item[11. ] $P[T_1, H_2] = P[T_1] * P[H_2] = 0.5 * 0.7 = 0.35$\\
\item[12. ] $P[one\ heads,\ one\ tails] = P[H_1,T_2] + P[T_1, H_2] = 0.15 + 0.35 = 0.5$\\
\item[13. ] {\Large \textbf{Solution: }$0.5$ }
\end{enumerate}
\newpage
\textbf{Problem 4}
\\
\begin{itemize}
\item[a) ] We are trying to solve for $P[C_0|H]$.  We will use Bayes Rule\\
$$ P[C_0\ |\ H] = \frac{P[H\ |\ C_0] * P[C_0]}{P[H]} $$
\\
We know $P[H\ |\ C_0]$ and $P[C_0]$, but we do not know $P[H]$, but we can solve for it. We know that
$$ P[C_0\ |\ H] + P[\overline{C_0}\ |\ H] = 1$$
\\
This means that
$$\frac{P[H\ |\ C_0] * P[C_0]}{P[H]} + \frac{P[H\ |\ C_1] * P[C_1]}{P[H]} = 1$$
\\
$$P[H] = P[H\ |\ C_0] * P[C_0] + P[H\ |\ C_1] * P[C_1]$$
\\
$$P[H] = 0.5* \frac{8}{11} + 0.8 * \frac{3}{11} = 0.581$$
\\
Now we know $P[H\ |\ C_0]$, $P[C_0]$, and $P[H]$, meaning we can solve for $P[C_0\ |\ H]$
\\
$$ P[C_0\ |\ H] = \frac{P[H\ |\ C_0] * P[C_0]}{P[H]} = \frac{0.5 * \frac{8}{11}}{.581} = 62.26\%$$\\
\begin{center}
{\Large \textbf{Solution = $62.26\%$} }
\end{center}
\newpage	
\item[b) ] 
$$ P[C_0\ |\ HH] = \frac{P[HH\ |\ C_0] * P[C_0]}{P[HH]} $$
\\
$$\frac{P[HH\ |\ C_0] * P[C_0]}{P[HH]} + \frac{P[HH\ |\ C_1] * P[C_1]}{P[HH]} = 1$$
\\
$$P[HH] = P[HH\ |\ C_0] * P[C_0] + P[HH\ |\ C_1] * P[C_1]$$
\\
$$P[HH] = ((0.5 * 0.5) * \frac{8}{11}) + ((0.8 * 0.8) * \frac{3}{11}) = 0.35636$$
\\
$$ P[C_0\ |\ HH] = \frac{0.25 * \frac{8}{11}}{0.35656} = 51.02\% $$
\\
\begin{center}
{\Large \textbf{Solution: $51.02\%$} }
\end{center}
\newpage
\item[c) ] $$ P[C_0\ |\ 1\ Head\ and\ 1\ Tail] = \frac{P[1\ Head\ and\ 1\ Tail\ |\ C_0]P[C_0]}{P[1\ Head\ and\ 1\ Tail]}$$
\\
$$ \frac{P[1\ Head\ and\ 1\ Tail\ |\ C_0]P[C_0]}{P[1\ Head\ and\ 1\ Tail]} +  \frac{P[1\ Head\ and\ 1\ Tail\ |\ C_1]P[C_1]}{P[1\ Head\ and\ 1\ Tail]} = 1$$
\\
$$P[1\ Head\ and\ 1\ Tail] = P[1\ Head\ and\ 1\ Tail\ |\ C_0]P[C_0] + P[1\ Head\ and\ 1\ Tail\ |\ C_1]P[C_1]$$
\\
$$P[1\ Head\ and\ 1\ Tail\ |\ C_0] = P[H_1,\ T_2\ |\ C_0] + P[T_1, H_2\ |\ C_0]$$
\\
$$P[1\ Head\ and\ 1\ Tail\ |\ C_0] = (0.5 * 0.5) + (0.5 * 0.5) = 0.5$$
\\
$$P[1\ Head\ and\ 1\ Tail\ |\ C_1] = P[H_1,\ T_2\ |\ C_1] + P[T_1, H_2\ |\ C_1]$$
\\
$$P[1\ Head\ and\ 1\ Tail\ |\ C_1] = (0.8 * 0.2) + (0.2 * 0.8) = 0.32$$
\\
$$P[1\ Head\ and\ 1\ Tail] = (0.5 * \frac{8}{11}) + (0.32 * \frac{3}{11}) = 0.451$$
\\
$$P[C_0\ |\ 1\ Head\ and\ 1\ Tail] = \frac{0.5 * \frac{8}{11}}{0.451} = 80.63\%$$
\\
\begin{center}
{\Large \textbf{Solution: $80.63\%$} }
\end{center}
\end{itemize}
\newpage
\textbf{Problem 5}
\\
\begin{center}
\textbf{We want to know the probability of the second ball being black when we know the first ball was black.  This only happens when we are in Urn 1, so we are trying to find out $P[U_1\ |\ B]$}
\end{center}
$$ P[U_1\ |\ B] = \frac{P[B\ |\ U_1] * P[U_1]}{P[B]}$$
\\
$$P[U_1\ |\ B] + P[\overline{U_1}\ |\ B] = 1$$
\\
$$P[U_1\ |\ B] + P[U_2\ |\ B] + P[U_3\ |\ B] = 1$$
\\
$$\frac{P[B\ |\ U_1] * P[U_1]}{P[B]} + \frac{P[B\ |\ U_2] * P[U_2]}{P[B]} + \frac{P[B\ |\ U_3] * P[U_3]}{P[B]} = 1$$
\\
$$P[B] = P[B\ |\ U_1] * P[U_1] + P[B\ |\ U_2] * P[U_2] + P[B\ |\ U_3] * P[U_3]$$
\\
$$P[B] = (1 * \frac{1}{3}) + (0 * \frac{1}{3}) + (0.5 * \frac{1}{3}) = \frac{1}{2}$$
\\
$$ P[U_1\ |\ B] = \frac{1 * \frac{1}{3}}{\frac{1}{2}} = \frac{2}{3}$$
\\
\begin{center}
{\huge \textbf{Solution: $\frac{2}{3}$} }
\end{center}
\newpage
\textbf{Problem 6}
\\
\begin{enumerate}
\item[a) ] To find the expected value of questions asked, we must look at the graph and find out how many questions will be asked for each value on the Dice.  Then we multiply each of those question numbers by the probability of that dice roll.\\ 
\\
$$Expected\ Value\ Questions\ = (0.25 * 1) + (0.25 * 3) + (0.20 * 3) + (0.15 * 3) + (0.10 * 4) + (0.05 * 4)$$
\\
$$Expected\ Value\ D_1\ = 2.65$$

\begin{center}
{\Large \textbf{Solution: $2.65$}}
\end{center}
\vspace{20 mm}
 \item[b) ] {\Large $Entropy\ = \sum\limits_{i=1}^n (P[i] * log_2(\frac{1}{P[i]}))$}\\
 $$= (.25 * log_2(\frac{1}{.25})) + (.25 * log_2(\frac{1}{.25})) + (.20 * log_2(\frac{1}{.20})) + (.15 * log_2(\frac{1}{.15})) + (.10 * log_2(\frac{1}{.10})) + (.05 * log_2(\frac{1}{.05}))$$
 \\
 $$ = 2.42$$
 \begin{center}
{ \Large \textbf{Solution: $2.42$}}
 \end{center}
\end{enumerate}




\end{document}